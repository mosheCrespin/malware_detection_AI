{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "##imports"
   ],
   "execution_count": 561,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "outputs": [],
   "source": [
    "# Imports\n",
    "import statistics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np # Support for large arrays and matrices, along with high-level mathematical functions.\n",
    "import seaborn as sns # Graphing/Plotting module.\n",
    "import pandas as pd # CSV handling with operations on tabular data.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read Data and Preprocess it to fit into DeepMAL model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "outputs": [],
   "source": [
    "# Read Data\n",
    "'''\n",
    "There are 2 datasets available for you to use -\n",
    "1. 'mta'\n",
    "2. 'ustc'\n",
    "Make sure that\n",
    "the path to the .csv files is correct. the following code loads the data from .csv file\n",
    "into a DataFrame.\n",
    "'''\n",
    "method = \"malware_family\"\n",
    "dataset_type = 'mta' # or 'ustc'\n",
    "submission_type = 'test'\n",
    "filepath = f'./datasets/{dataset_type}/xy_train.csv'\n",
    "df = pd.read_csv(filepath)\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Data exploration"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# sns.set(rc={'figure.figsize':(30,8)})\n",
    "# sns.countplot(data=df, x='malware_family')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "heatmap\n",
    "\"\"\"\n",
    "# sns.heatmap(df.corr(), cmap='Blues')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "Plotting the amount of bidirectional bytes in the session/flow (on average) of each class.\n",
    "Along with the standard deviation.\n",
    "'''\n",
    "# sns.set(rc={'figure.figsize':(30,8)})\n",
    "# sns.barplot(data=df, y='bidirectional_bytes', x='malware_family')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sns.set(rc={'figure.figsize':(15,8)})\n",
    "# sns.lineplot(data=df, y='src2dst_packets', x='dst2src_packets')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "outputs": [],
   "source": [
    "\n",
    "Y = df[method]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "dealing with matrix objects"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "outputs": [],
   "source": [
    "def strmatrix_to_floatmatrix(str_mat):\n",
    "    ans = []\n",
    "    indices_start = [i for i, x in enumerate(str_mat) if x == '[']\n",
    "    indices_end = [i for i, x in enumerate(str_mat) if x == ']']\n",
    "    i = 1\n",
    "    j = 0\n",
    "    while i < len(indices_start) and j < len(indices_end) - 1:\n",
    "        # print(mat[indices_start[i]:indices_end[j]+1])\n",
    "        ans.append(ast.literal_eval(str_mat[indices_start[i]:indices_end[j] + 1]))\n",
    "        i += 1\n",
    "        j += 1\n",
    "    return ans\n",
    "\n",
    "from statistics import variance\n",
    "def math_list(l):\n",
    "    if method == 'label':\n",
    "        return sum(l)\n",
    "    if method == 'malware_family':\n",
    "        return variance(l)\n",
    "\n",
    "\n",
    "def create_features_from_mat(df_to_ret,col_name, df_matrix):\n",
    "    features = dict()\n",
    "    features_counter = len(strmatrix_to_floatmatrix(df_matrix[col_name][0]))\n",
    "    mat_saver = []\n",
    "\n",
    "    for i in range(len(df_matrix[col_name])):  # iterate over the rows\n",
    "        mat_saver.append(strmatrix_to_floatmatrix(df_matrix[col_name][i]))\n",
    "    for i in range(len(df_matrix[col_name])):\n",
    "        for j in range(features_counter):\n",
    "            if j not in features:\n",
    "                features[j] = []\n",
    "            features[j].append(math_list(mat_saver[i][j]))\n",
    "    for i in range(features_counter):\n",
    "        feature_name = f\"{col_name}_{i}\"\n",
    "        df_to_ret.insert(0,feature_name, features[i])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "outputs": [],
   "source": [
    "def mat_preproccesing(df_to_proccess, df_mat):\n",
    "    for col_name in df_mat.columns:\n",
    "        create_features_from_mat(df_to_proccess,col_name, df_mat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "outputs": [],
   "source": [
    "# deal with list object\n",
    "import ast\n",
    "def create_features_from_list(df_to_ret,col_name, df_list):\n",
    "    ans=[]\n",
    "    for i in range(len(df_list[col_name])):\n",
    "        ans.append(sum(ast.literal_eval(df_list[col_name][i])))\n",
    "    feature_name = f\"{col_name}_0\"\n",
    "    df_to_ret.insert(0, feature_name, ans)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "outputs": [],
   "source": [
    "def unique_and_null(dataframe):\n",
    "    uniqe = []\n",
    "    nulls =[]\n",
    "    for col_name in dataframe.columns:\n",
    "        if dataframe[col_name].dtype in ('int64','float64') :\n",
    "            unique_count = len(dataframe[col_name].unique())\n",
    "            # print(f\"feature '{col_name}' has {unique_count} unique categories\")\n",
    "            if unique_count == 1:\n",
    "                uniqe.append(col_name)\n",
    "    #null cols\n",
    "    null_cols= dataframe.isnull().sum()\n",
    "    null_cols = dict(null_cols)\n",
    "    for name, num in null_cols.items():\n",
    "        if num > 0:\n",
    "            nulls.append(name)\n",
    "    return nulls, uniqe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "outputs": [],
   "source": [
    "def get_objects(dataframe):\n",
    "    ans = []\n",
    "    for i in dataframe.columns:\n",
    "        if dataframe[i].dtype == 'object':\n",
    "            ans.append(i)\n",
    "    return ans"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "outputs": [],
   "source": [
    "def preprocces(df_pre, is_predict: bool, df_mat, df_list):\n",
    "    set_for_x= {'src_ip', 'src_mac','dst_ip', 'dst_mac','dst_oui','src_oui','src_port', 'dst_port',\n",
    "         'bidirectional_last_seen_ms','bidirectional_first_seen_ms','src2dst_first_seen_ms','src2dst_last_seen_ms','dst2src_first_seen_ms','dst2src_last_seen_ms'}\n",
    "    nulls, uniqe = unique_and_null(df_pre)\n",
    "    objects = get_objects(df_pre)\n",
    "    set_for_x.update(nulls)\n",
    "    set_for_x.update(uniqe)\n",
    "    set_for_x.update(objects)\n",
    "    if is_predict:\n",
    "        if 'file_name' in set_for_x:\n",
    "            set_for_x.remove('file_name')\n",
    "        if 'label' in set_for_x:\n",
    "            set_for_x.remove('label')\n",
    "        if 'malware_family' in set_for_x:\n",
    "            set_for_x.remove('malware_family')\n",
    "\n",
    "    df_pre = df_pre.drop(list(set_for_x), 1)\n",
    "    # proccess matrix\n",
    "    mat_preproccesing(df_pre, df_mat)\n",
    "    # proccess list\n",
    "    create_features_from_list(df_pre, 'udps.n_bytes', df_list)\n",
    "    return df_pre"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "outputs": [],
   "source": [
    "def mat_list_loader(path: str):\n",
    "    mat_ = ['udps.protocol_header_fields', 'udps.n_bytes_per_packet', 'udps.stnn_image']\n",
    "    list_ = ['udps.n_bytes']\n",
    "    df_mat = pd.read_csv(path, usecols=mat_ )\n",
    "    df_list = pd.read_csv(path, usecols=list_ )\n",
    "    return df_mat, df_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_14652/109357539.py:17: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df_pre = df_pre.drop(list(set_for_x), 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20493 entries, 0 to 20492\n",
      "Data columns (total 92 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   udps.n_bytes_0                   20493 non-null  float64\n",
      " 1   udps.stnn_image_4                20493 non-null  float64\n",
      " 2   udps.stnn_image_3                20493 non-null  float64\n",
      " 3   udps.stnn_image_2                20493 non-null  float64\n",
      " 4   udps.stnn_image_1                20493 non-null  float64\n",
      " 5   udps.stnn_image_0                20493 non-null  float64\n",
      " 6   udps.n_bytes_per_packet_1        20493 non-null  float64\n",
      " 7   udps.n_bytes_per_packet_0        20493 non-null  float64\n",
      " 8   udps.protocol_header_fields_31   20493 non-null  float64\n",
      " 9   udps.protocol_header_fields_30   20493 non-null  float64\n",
      " 10  udps.protocol_header_fields_29   20493 non-null  float64\n",
      " 11  udps.protocol_header_fields_28   20493 non-null  float64\n",
      " 12  udps.protocol_header_fields_27   20493 non-null  float64\n",
      " 13  udps.protocol_header_fields_26   20493 non-null  float64\n",
      " 14  udps.protocol_header_fields_25   20493 non-null  float64\n",
      " 15  udps.protocol_header_fields_24   20493 non-null  float64\n",
      " 16  udps.protocol_header_fields_23   20493 non-null  float64\n",
      " 17  udps.protocol_header_fields_22   20493 non-null  float64\n",
      " 18  udps.protocol_header_fields_21   20493 non-null  float64\n",
      " 19  udps.protocol_header_fields_20   20493 non-null  float64\n",
      " 20  udps.protocol_header_fields_19   20493 non-null  float64\n",
      " 21  udps.protocol_header_fields_18   20493 non-null  float64\n",
      " 22  udps.protocol_header_fields_17   20493 non-null  float64\n",
      " 23  udps.protocol_header_fields_16   20493 non-null  float64\n",
      " 24  udps.protocol_header_fields_15   20493 non-null  float64\n",
      " 25  udps.protocol_header_fields_14   20493 non-null  float64\n",
      " 26  udps.protocol_header_fields_13   20493 non-null  float64\n",
      " 27  udps.protocol_header_fields_12   20493 non-null  float64\n",
      " 28  udps.protocol_header_fields_11   20493 non-null  float64\n",
      " 29  udps.protocol_header_fields_10   20493 non-null  float64\n",
      " 30  udps.protocol_header_fields_9    20493 non-null  float64\n",
      " 31  udps.protocol_header_fields_8    20493 non-null  float64\n",
      " 32  udps.protocol_header_fields_7    20493 non-null  float64\n",
      " 33  udps.protocol_header_fields_6    20493 non-null  float64\n",
      " 34  udps.protocol_header_fields_5    20493 non-null  float64\n",
      " 35  udps.protocol_header_fields_4    20493 non-null  float64\n",
      " 36  udps.protocol_header_fields_3    20493 non-null  float64\n",
      " 37  udps.protocol_header_fields_2    20493 non-null  float64\n",
      " 38  udps.protocol_header_fields_1    20493 non-null  float64\n",
      " 39  udps.protocol_header_fields_0    20493 non-null  float64\n",
      " 40  protocol                         20493 non-null  int64  \n",
      " 41  ip_version                       20493 non-null  int64  \n",
      " 42  bidirectional_duration_ms        20493 non-null  int64  \n",
      " 43  bidirectional_packets            20493 non-null  int64  \n",
      " 44  bidirectional_bytes              20493 non-null  int64  \n",
      " 45  src2dst_duration_ms              20493 non-null  int64  \n",
      " 46  src2dst_packets                  20493 non-null  int64  \n",
      " 47  src2dst_bytes                    20493 non-null  int64  \n",
      " 48  dst2src_duration_ms              20493 non-null  int64  \n",
      " 49  dst2src_packets                  20493 non-null  int64  \n",
      " 50  dst2src_bytes                    20493 non-null  int64  \n",
      " 51  bidirectional_min_ps             20493 non-null  int64  \n",
      " 52  bidirectional_mean_ps            20493 non-null  float64\n",
      " 53  bidirectional_stddev_ps          20493 non-null  float64\n",
      " 54  bidirectional_max_ps             20493 non-null  int64  \n",
      " 55  src2dst_min_ps                   20493 non-null  int64  \n",
      " 56  src2dst_mean_ps                  20493 non-null  float64\n",
      " 57  src2dst_stddev_ps                20493 non-null  float64\n",
      " 58  src2dst_max_ps                   20493 non-null  int64  \n",
      " 59  dst2src_min_ps                   20493 non-null  int64  \n",
      " 60  dst2src_mean_ps                  20493 non-null  float64\n",
      " 61  dst2src_stddev_ps                20493 non-null  float64\n",
      " 62  dst2src_max_ps                   20493 non-null  int64  \n",
      " 63  bidirectional_min_piat_ms        20493 non-null  int64  \n",
      " 64  bidirectional_mean_piat_ms       20493 non-null  float64\n",
      " 65  bidirectional_stddev_piat_ms     20493 non-null  float64\n",
      " 66  bidirectional_max_piat_ms        20493 non-null  int64  \n",
      " 67  src2dst_min_piat_ms              20493 non-null  int64  \n",
      " 68  src2dst_mean_piat_ms             20493 non-null  float64\n",
      " 69  src2dst_stddev_piat_ms           20493 non-null  float64\n",
      " 70  src2dst_max_piat_ms              20493 non-null  int64  \n",
      " 71  dst2src_min_piat_ms              20493 non-null  int64  \n",
      " 72  dst2src_mean_piat_ms             20493 non-null  float64\n",
      " 73  dst2src_stddev_piat_ms           20493 non-null  float64\n",
      " 74  dst2src_max_piat_ms              20493 non-null  int64  \n",
      " 75  bidirectional_syn_packets        20493 non-null  int64  \n",
      " 76  bidirectional_ack_packets        20493 non-null  int64  \n",
      " 77  bidirectional_psh_packets        20493 non-null  int64  \n",
      " 78  bidirectional_rst_packets        20493 non-null  int64  \n",
      " 79  bidirectional_fin_packets        20493 non-null  int64  \n",
      " 80  src2dst_syn_packets              20493 non-null  int64  \n",
      " 81  src2dst_ack_packets              20493 non-null  int64  \n",
      " 82  src2dst_psh_packets              20493 non-null  int64  \n",
      " 83  src2dst_rst_packets              20493 non-null  int64  \n",
      " 84  src2dst_fin_packets              20493 non-null  int64  \n",
      " 85  dst2src_syn_packets              20493 non-null  int64  \n",
      " 86  dst2src_ack_packets              20493 non-null  int64  \n",
      " 87  dst2src_psh_packets              20493 non-null  int64  \n",
      " 88  dst2src_rst_packets              20493 non-null  int64  \n",
      " 89  dst2src_fin_packets              20493 non-null  int64  \n",
      " 90  application_is_guessed           20493 non-null  int64  \n",
      " 91  udps.handshake_packets_duration  20493 non-null  float64\n",
      "dtypes: float64(53), int64(39)\n",
      "memory usage: 14.4 MB\n"
     ]
    }
   ],
   "source": [
    "X = df\n",
    "df_mat , df_list = mat_list_loader(filepath)\n",
    "X = preprocces(X, False, df_mat, df_list)\n",
    "X.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "outputs": [],
   "source": [
    "'''\n",
    "features-> Heatmap\n",
    "'''\n",
    "# from matplotlib import pyplot as plt\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# #get correlations of each features in dataset\n",
    "# corrmat = X.corr()\n",
    "# top_corr_features = corrmat.index\n",
    "# plt.figure(figsize=(250,250))\n",
    "#\n",
    "# g=sns.heatmap(X[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                    test_size=0.20,  # train\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Feat_names     F_Scores\n",
      "3   udps.protocol_header_fields_0  2100.499124\n",
      "19         application_is_guessed   723.721442\n",
      "1       udps.n_bytes_per_packet_1   258.799639\n",
      "2       udps.n_bytes_per_packet_0   229.497004\n",
      "0                  udps.n_bytes_0   107.505717\n",
      "12      bidirectional_syn_packets    89.207836\n",
      "16            dst2src_syn_packets    89.066698\n",
      "14            src2dst_syn_packets    83.297769\n",
      "7                 dst2src_mean_ps    74.886682\n",
      "8               dst2src_stddev_ps    73.634823\n",
      "4                        protocol    67.743304\n",
      "9                  dst2src_max_ps    58.867360\n",
      "15            src2dst_fin_packets    53.207961\n",
      "13      bidirectional_fin_packets    44.574852\n",
      "5           bidirectional_mean_ps    41.725075\n",
      "17            dst2src_rst_packets    39.053002\n",
      "18            dst2src_fin_packets    26.877609\n",
      "11            src2dst_max_piat_ms    26.223781\n",
      "10      bidirectional_max_piat_ms    25.959316\n",
      "6         bidirectional_stddev_ps    24.669222\n"
     ]
    }
   ],
   "source": [
    "# chi2 f_classif\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif,chi2\n",
    "selector = SelectKBest(f_classif, k = 20)\n",
    "\n",
    "X_new = selector.fit_transform(x_train, y_train)\n",
    "names = X.columns.values[selector.get_support()]\n",
    "scores = selector.scores_[selector.get_support()]\n",
    "names_scores = list(zip(names, scores))\n",
    "ns_df = pd.DataFrame(data = names_scores, columns=['Feat_names', 'F_Scores'])\n",
    "#Sort the dataframe for better visualization\n",
    "ns_df_sorted = ns_df.sort_values(['F_Scores', 'Feat_names'], ascending = [False, True])\n",
    "list_df = ns_df_sorted.values.tolist()\n",
    "print(ns_df_sorted)\n",
    "features_list = []\n",
    "for i in list_df:\n",
    "    features_list.append(i[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##fit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=20, random_state=7)),\n",
    "    ('ABC',DecisionTreeClassifier(random_state=6)),\n",
    "    ('GBC',KNeighborsClassifier(n_neighbors=5))\n",
    "    # ,('AdaBoost', AdaBoostClassifier(n_estimators=10,random_state=7) )\n",
    "    # ,('svm',SVC(random_state = 7))\n",
    "    ]\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator= LogisticRegression(solver='lbfgs', max_iter=100, random_state= 7)\n",
    ")\n",
    "\n",
    "model = clf\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\moshe\\pycharmprojects\\pythonproject11\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": "StackingClassifier(estimators=[('rf',\n                                RandomForestClassifier(n_estimators=20,\n                                                       random_state=7)),\n                               ('ABC', DecisionTreeClassifier(random_state=6)),\n                               ('GBC', KNeighborsClassifier())],\n                   final_estimator=LogisticRegression(random_state=7))"
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train[features_list], y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  bazaloader       0.96      0.85      0.90       105\n",
      "      benign       0.99      1.00      0.99      2049\n",
      "      dridex       0.79      0.65      0.72        89\n",
      "      emotet       0.99      0.99      0.99       672\n",
      "    hancitor       0.87      0.88      0.88       398\n",
      "      icedid       0.84      0.77      0.80       139\n",
      "      qakbot       0.85      0.91      0.88       478\n",
      "       valak       0.96      0.91      0.93       123\n",
      "     zloader       0.90      0.78      0.84        46\n",
      "\n",
      "    accuracy                           0.95      4099\n",
      "   macro avg       0.91      0.86      0.88      4099\n",
      "weighted avg       0.95      0.95      0.95      4099\n",
      "\n",
      "accuracy is:  0.9504757257867773\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score  #check recall, acucuracy and precision\\n\n",
    "y_pred = model.predict(x_test[features_list])\n",
    "print(classification_report(y_true = y_test, y_pred = y_pred))\n",
    "\n",
    "print(\"accuracy is: \", accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_14652/109357539.py:17: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df_pre = df_pre.drop(list(set_for_x), 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filepath = f'./datasets/{dataset_type}/x_{submission_type}.csv'\n",
    "df_test = pd.read_csv(filepath)\n",
    "df_mat_ , df_list_ = mat_list_loader(filepath)\n",
    "x_submission = preprocces(df_test, True,df_mat_, df_list_ )\n",
    "predictions = model.predict(x_submission[features_list])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "np.savetxt(f'{dataset_type}_{submission_type}_{method}.txt', enc.fit_transform(predictions), fmt='%2d')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}